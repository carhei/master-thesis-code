\documentclass[../main.tex]{subfiles}

\begin{document}

In this chapter, the results of the thesis and possibilities for future improvements will be discussed. Learning a control for a system while at the same time ensuring constraint satisfaction is a promising approach because one does not have to rely on model accuracy. This thesis presents a way to ensure safety with HJI reachability analysis while learning a control with Reinforcement Learning. Compared to the approach presented in \cite{akametalu2014reachability}, the method has been extended to incorporate exploration which improves disturbance and policy estimation considerably. The algorithm has however some weak points that could be interesting to look at in future work. \par
Firstly, the collaboration of the different methods is not satisfactory in some regards. The safety loop of the algorithm solely passes an estimate of the disturbance bounds to the learning loop and runs apart from that completely separate. It would be preferable to pass some more information from the safety loop to the learning loop to warm-start the Reinforcement Learning algorithm. For instance, the policy could be initialized to the safe control from the safety algorithm or conclusions about transition probabilities could be drawn from the recorded samples. Furthermore, the fact that the algorithm runs on two different time scales is not quite optimal. Finding a way how to run both loops on the same time scale might increase the efficiency of the algorithm substantially.\par
Moreover, the disturbance estimation could possibly be improved. The Gaussian Process regression is implemented batchwise with batches at $1000$ samples each due to the computational complexity of the method. The disturbance estimation might be improved considerably by employing a recursive method that takes all recorded samples into account. \par
Finally, the most significant improvement could be made by guaranteeing that the system never leaves the safe set. The two main problems that cause the system to sporadically leave the safe set in the current algorithm are known: Firstly, the numerical differentiation of the recorded data points leads to a faulty disturbance estimate. This distorts the safe set. Secondly, the safety check is not performed continuously such that the system can leave the safe set in between two samples. The problem could for instance be tackled by shrinking the safe set with regard to the sampling time.\par
In summary, it can be said that ideas from this thesis could be a good starting point for future research. Even though some adjustments, i.e. a closer integration of the different methods, should be made, the approach of safe learning for control applications is really interesting and could overcome some of the limitation of traditional control.

\end{document}